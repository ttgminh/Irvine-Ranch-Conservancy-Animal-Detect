{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [00:02<00:00, 62.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "\n",
    "#Specify the image size that we are resizing to and the confidence level that we are filtering by\n",
    "IMAGE_SIZE = 300  #Make change to this value to resize the image to a different size\n",
    "CONFIDENCE_LEVEL = 0.4 #Make change to this value to filter by a different confidence level\n",
    "\n",
    "#Specify the split ratio for the train and test sets, should sum up to 1\n",
    "test_ratio = 0.3 #Make change to this value to change the ratio of the test set\n",
    "train_ratio = 0.7 #Make change to this value to change the ratio of the train set\n",
    "\n",
    "\n",
    "######################################################################################################################################################################\n",
    "\n",
    "# Load the data\n",
    "with open('image_recognition_file.json') as f: #the image_recognition_file.json file is the output from EcoAssist MegaDetector\n",
    "    data = json.load(f)\n",
    "\n",
    "# Ensure the necessary directories exist\n",
    "os.makedirs('train', exist_ok=True)\n",
    "os.makedirs('test', exist_ok=True)\n",
    "\n",
    "def get_square_crop_coords(bbox, img_shape):\n",
    "    x, y, w, h = bbox\n",
    "    img_w, img_h = img_shape\n",
    "    \n",
    "    # Convert bbox from relative to absolute coordinates\n",
    "    x = int(x * img_w)\n",
    "    y = int(y * img_h)\n",
    "    w = int(w * img_w)\n",
    "    h = int(h * img_h)\n",
    "    \n",
    "    side_length = max(w, h)\n",
    "    center_x = x + w // 2\n",
    "    center_y = y + h // 2\n",
    "    \n",
    "    x1 = max(center_x - side_length // 2, 0)\n",
    "    y1 = max(center_y - side_length // 2, 0)\n",
    "    x2 = min(center_x + side_length // 2, img_w)\n",
    "    y2 = min(center_y + side_length // 2, img_h)\n",
    "    \n",
    "    # Adjust to ensure square dimensions\n",
    "    side_length = min(x2 - x1, y2 - y1)\n",
    "    return x1, y1, x1 + side_length, y1 + side_length\n",
    "\n",
    "# List to hold file paths and their respective species\n",
    "file_paths = []\n",
    "species_labels = []\n",
    "\n",
    "# Process images\n",
    "for img_data in tqdm(data['images']):\n",
    "    file_path = img_data['file']\n",
    "    species = file_path.split('/')[0]\n",
    "    img = Image.open(file_path)\n",
    "    \n",
    "    if 'detections' in img_data:\n",
    "        for i, detection in enumerate(img_data['detections']):\n",
    "            if detection['category'] == \"1\" and detection['conf'] >= CONFIDENCE_LEVEL: # Only include images with a confidence of 0.4 or higher and a category of 1(animal)\n",
    "                bbox = detection['bbox']\n",
    "                x1, y1, x2, y2 = get_square_crop_coords(bbox, img.size)\n",
    "                cropped_img = img.crop((x1, y1, x2, y2))\n",
    "                resized_img = cropped_img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "                \n",
    "                # Convert RGBA to RGB if necessary\n",
    "                if resized_img.mode == 'RGBA':\n",
    "                    resized_img = resized_img.convert('RGB')\n",
    "                \n",
    "                # Ensure directories exist\n",
    "                os.makedirs(f'train/{species}', exist_ok=True)\n",
    "                os.makedirs(f'test/{species}', exist_ok=True)\n",
    "                \n",
    "                # Save resized image to temporary path with a unique name\n",
    "                temp_path = f'temp/{species}_{os.path.basename(file_path).split(\".\")[0]}_{i}.jpg'\n",
    "                os.makedirs('temp', exist_ok=True)\n",
    "                resized_img.save(temp_path)\n",
    "                \n",
    "                file_paths.append(temp_path)\n",
    "                species_labels.append(species)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(file_paths, species_labels, test_size=test_ratio, stratify=species_labels)\n",
    "\n",
    "# Save images to respective directories\n",
    "for file_list, labels, dir_name in zip([train_files, test_files], [train_labels, test_labels], ['train', 'test']):\n",
    "    for i, f in enumerate(file_list):\n",
    "        species = labels[i]\n",
    "        output_path = f'{dir_name}/{species}/{os.path.basename(f)}'\n",
    "        copyfile(f, output_path)\n",
    "\n",
    "print(\"Processing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
